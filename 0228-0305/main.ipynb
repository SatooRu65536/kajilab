{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int, batch_first: bool) -> None:\n",
    "        \"\"\"\n",
    "            層を定義\n",
    "\n",
    "            Args:\n",
    "                input_dim (int): 入力の次元\n",
    "                output_dim (int): 出力の次元\n",
    "                hidden_dim (int): 隠れ層の次元\n",
    "                batch_first (int): 入力テンソルの形式を変更する\n",
    "\n",
    "            Returns:\n",
    "                None\n",
    "        \"\"\"\n",
    "        super(Predictor, self).__init__()\n",
    "        self.nn = torch.nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=batch_first\n",
    "        )\n",
    "        self.output_layer = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, inputs, hidden0=None):\n",
    "        \"\"\"\n",
    "            どのように計算を伝搬していくかを定義\n",
    "\n",
    "            Args:\n",
    "                inputs (array): 入力する時系列データ\n",
    "        \"\"\"\n",
    "        h, _ = self.nn(inputs, hidden0)\n",
    "        output = self.output_layer(h[:, -1])\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        hidden_dim: int,\n",
    "        batch_first: bool,\n",
    "        lr: float,\n",
    "        benchmark: bool,\n",
    "    ) -> None:\n",
    "        self.labels = [\"stay\", \"walk\", \"jog\", \"skip\", \"stUp\", \"stDown\"]\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"device：\", self.device)\n",
    "        self.model = Predictor(input_dim, output_dim, hidden_dim, batch_first).to(\n",
    "            self.device\n",
    "        )\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        # self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "\n",
    "        torch.backends.cudnn.benchmark = benchmark\n",
    "\n",
    "    def make_dataset(self, sequence_length: int, person_id: str, path: str):\n",
    "        files = [\n",
    "            {\n",
    "                \"label\": l,\n",
    "                \"acc\": str(\n",
    "                    list(\n",
    "                        pathlib.Path(f\"{path}/{i+1}_{l}/{person_id}\").glob(\"*-acc.csv\")\n",
    "                    )[0]\n",
    "                ),\n",
    "                \"gyro\": str(\n",
    "                    list(\n",
    "                        pathlib.Path(f\"{path}/{i+1}_{l}/{person_id}\").glob(\"*-gyro.csv\")\n",
    "                    )[0]\n",
    "                ),\n",
    "                \"pressure\": str(\n",
    "                    list(\n",
    "                        pathlib.Path(f\"{path}/{i+1}_{l}/{person_id}\").glob(\n",
    "                            \"*-pressure.csv\"\n",
    "                        )\n",
    "                    )[0]\n",
    "                ),\n",
    "            }\n",
    "            for i, l in enumerate(self.labels)\n",
    "        ]\n",
    "\n",
    "        df_acc = pd.concat(\n",
    "            [\n",
    "                pd.read_csv(\n",
    "                    f[\"acc\"], header=None, names=[\"time\", \"x\", \"y\", \"z\"]\n",
    "                ).assign(label=f[\"label\"])\n",
    "                for f in files\n",
    "            ]\n",
    "        )\n",
    "        df_gyro = pd.concat(\n",
    "            [\n",
    "                pd.read_csv(f[\"gyro\"], header=None, names=[\"time\", \"pressure\"]).assign(\n",
    "                    label=f[\"label\"]\n",
    "                )\n",
    "                for f in files\n",
    "            ]\n",
    "        )\n",
    "        df_pressure = pd.concat(\n",
    "            [\n",
    "                pd.read_csv(\n",
    "                    f[\"pressure\"], header=None, names=[\"time\", \"x\", \"y\", \"z\"]\n",
    "                ).assign(label=f[\"label\"])\n",
    "                for f in files\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        dataset_inputs = []\n",
    "        dataset_labels = []\n",
    "        dataset_times = []\n",
    "\n",
    "        # self.df_acc を時系列データに変換\n",
    "        for i, row in enumerate(df_acc.itertuples()):\n",
    "            # dataframe の長さを超える場合は終了\n",
    "            if i + sequence_length > len(df_acc):\n",
    "                break\n",
    "            # ラベルが変わる場合はスキップ\n",
    "            if i > 0 and df_acc.iloc[i - 1].label != row.label:\n",
    "                continue\n",
    "\n",
    "            dataset_inputs.append(\n",
    "                df_acc.iloc[i : i + sequence_length]\n",
    "                .drop([\"time\", \"label\"], axis=1)\n",
    "                .values\n",
    "            )\n",
    "            dataset_labels.append(row.label)\n",
    "            dataset_times.append(row.time)\n",
    "\n",
    "        return dataset_inputs, dataset_labels, dataset_times\n",
    "\n",
    "    def labels2int(self, labels: list):\n",
    "        if type(labels[0]) == list:\n",
    "            return [self.labels2int(label) for label in labels]\n",
    "        return [self.labels.index(label) for label in labels]\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_inputs: list,\n",
    "        train_labels: list,\n",
    "        test_inputs: list,\n",
    "        test_labels: list,\n",
    "        epoch_num: int,\n",
    "        batch_size: int,\n",
    "        sequence_length: int,\n",
    "    ):\n",
    "        train_batch_num = len(train_inputs) // batch_size\n",
    "        test_batch_num = len(test_inputs) // batch_size\n",
    "\n",
    "        for epoch in range(epoch_num):\n",
    "            print(\"-\" * 20)\n",
    "            print(f\"Epoch {epoch+1}/{epoch_num}\")\n",
    "            train_loss = 0.0\n",
    "            test_loss = 0.0\n",
    "            shuffled_train_inputs, shuffled_train_labels = shuffle(\n",
    "                train_inputs, train_labels\n",
    "            )\n",
    "\n",
    "            np.savetxt(\n",
    "                \"shuffled_train_inputs.csv\",\n",
    "                np.array(shuffled_train_inputs).reshape(\n",
    "                    -1, np.array(shuffled_train_inputs).shape[-1]\n",
    "                ),\n",
    "                delimiter=\",\",\n",
    "            )\n",
    "\n",
    "            for batch in range(train_batch_num):\n",
    "                start = batch * batch_size\n",
    "                end = start + batch_size\n",
    "\n",
    "                np_train_inputs = np.array(shuffled_train_inputs[start:end]).astype(\n",
    "                    np.float64\n",
    "                )\n",
    "                np_train_labels = np.array(shuffled_train_labels[start:end]).astype(\n",
    "                    np.int64\n",
    "                )\n",
    "                loss, _ = self.train_step(np_train_inputs, np_train_labels)\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            for batch in range(test_batch_num):\n",
    "                start = batch * batch_size\n",
    "                end = start + batch_size\n",
    "\n",
    "                loss, _ = self.train_step(\n",
    "                    np.array(test_inputs[start:end]).astype(np.float64),\n",
    "                    np.array(test_labels[start:end]).astype(np.int64),\n",
    "                )\n",
    "                test_loss += loss.item()\n",
    "\n",
    "            print(f\"loss: {train_loss / train_batch_num}\")\n",
    "            print(f'test_loss: {test_loss / test_batch_num}')\n",
    "\n",
    "    def train_step(self, inputs, labels):\n",
    "        inputs_tensor = torch.tensor(inputs, dtype=torch.float32).to(self.device)\n",
    "        labels_tensor = torch.tensor(labels).to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        preds = self.model(inputs_tensor)\n",
    "        loss = self.criterion(preds, labels_tensor)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device： cpu\n",
      "--------------------\n",
      "Epoch 1/1000\n",
      "loss: 1.630137525629579\n",
      "test_loss: 2.442890736094692\n",
      "--------------------\n",
      "Epoch 2/1000\n",
      "loss: 1.7019225055711311\n",
      "test_loss: 1.8877409361956412\n",
      "--------------------\n",
      "Epoch 3/1000\n",
      "loss: 1.540266997458642\n",
      "test_loss: 1.795748932319775\n",
      "--------------------\n",
      "Epoch 4/1000\n",
      "loss: 1.385672136879804\n",
      "test_loss: 1.7306678817983259\n",
      "--------------------\n",
      "Epoch 5/1000\n",
      "loss: 1.1404629349708557\n",
      "test_loss: 1.767101986366406\n",
      "--------------------\n",
      "Epoch 6/1000\n",
      "loss: 1.1020972488219278\n",
      "test_loss: 1.7500062919499582\n",
      "--------------------\n",
      "Epoch 7/1000\n",
      "loss: 0.9903440485920822\n",
      "test_loss: 1.7630002226745873\n",
      "--------------------\n",
      "Epoch 8/1000\n",
      "loss: 0.9252728592408331\n",
      "test_loss: 1.563580154326924\n",
      "--------------------\n",
      "Epoch 9/1000\n",
      "loss: 0.8774599046037909\n",
      "test_loss: 1.4735484447395593\n",
      "--------------------\n",
      "Epoch 10/1000\n",
      "loss: 0.918975033127425\n",
      "test_loss: 1.307259570088303\n",
      "--------------------\n",
      "Epoch 11/1000\n",
      "loss: 0.8698261415487841\n",
      "test_loss: 1.357031524181366\n",
      "--------------------\n",
      "Epoch 12/1000\n",
      "loss: 0.8585810946267948\n",
      "test_loss: 1.4697438164761192\n",
      "--------------------\n",
      "Epoch 13/1000\n",
      "loss: 0.8069249377177473\n",
      "test_loss: 1.3504774716862462\n",
      "--------------------\n",
      "Epoch 14/1000\n",
      "loss: 0.8139038827074202\n",
      "test_loss: 1.4385173603108055\n",
      "--------------------\n",
      "Epoch 15/1000\n",
      "loss: 0.7137377449033553\n",
      "test_loss: 1.5331655646625317\n",
      "--------------------\n",
      "Epoch 16/1000\n",
      "loss: 0.6469965586275385\n",
      "test_loss: 1.3593114562201918\n",
      "--------------------\n",
      "Epoch 17/1000\n",
      "loss: 0.6734755452264819\n",
      "test_loss: 1.2051068157480473\n",
      "--------------------\n",
      "Epoch 18/1000\n",
      "loss: 0.59989584498761\n",
      "test_loss: 1.2267674615508632\n",
      "--------------------\n",
      "Epoch 19/1000\n",
      "loss: 0.5436121351494078\n",
      "test_loss: 1.150569305608147\n",
      "--------------------\n",
      "Epoch 20/1000\n",
      "loss: 0.49687778956273143\n",
      "test_loss: 1.210970051455916\n",
      "--------------------\n",
      "Epoch 21/1000\n",
      "loss: 0.4641952242767602\n",
      "test_loss: 1.0792617133834905\n",
      "--------------------\n",
      "Epoch 22/1000\n",
      "loss: 0.4229095833735508\n",
      "test_loss: 1.1240284625898327\n",
      "--------------------\n",
      "Epoch 23/1000\n",
      "loss: 0.3361130912314382\n",
      "test_loss: 1.2746481916360688\n",
      "--------------------\n",
      "Epoch 24/1000\n",
      "loss: 0.3400556986269198\n",
      "test_loss: 0.9357172993191502\n",
      "--------------------\n",
      "Epoch 25/1000\n",
      "loss: 0.37263014236170994\n",
      "test_loss: 0.8313995380150644\n",
      "--------------------\n",
      "Epoch 26/1000\n",
      "loss: 0.3137943606431547\n",
      "test_loss: 0.8474366199551967\n",
      "--------------------\n",
      "Epoch 27/1000\n",
      "loss: 0.2930465969338752\n",
      "test_loss: 0.7688744732162409\n",
      "--------------------\n",
      "Epoch 28/1000\n",
      "loss: 0.27309067593070496\n",
      "test_loss: 0.7405989627566254\n",
      "--------------------\n",
      "Epoch 29/1000\n",
      "loss: 0.24836497605173735\n",
      "test_loss: 0.6977872604079414\n",
      "--------------------\n",
      "Epoch 30/1000\n",
      "loss: 0.21621218576961965\n",
      "test_loss: 0.731465765520146\n",
      "--------------------\n",
      "Epoch 31/1000\n",
      "loss: 0.23488287658741078\n",
      "test_loss: 0.6261328348987981\n",
      "--------------------\n",
      "Epoch 32/1000\n",
      "loss: 0.1992732516669652\n",
      "test_loss: 0.6658687324900376\n",
      "--------------------\n",
      "Epoch 33/1000\n",
      "loss: 0.24227043963445907\n",
      "test_loss: 0.4404368980934745\n",
      "--------------------\n",
      "Epoch 34/1000\n",
      "loss: 0.2283972360749255\n",
      "test_loss: 0.5662162800629934\n",
      "--------------------\n",
      "Epoch 35/1000\n",
      "loss: 0.19396670396325358\n",
      "test_loss: 0.6183168166562131\n",
      "--------------------\n",
      "Epoch 36/1000\n",
      "loss: 0.20718095726088473\n",
      "test_loss: 0.43612806041512575\n",
      "--------------------\n",
      "Epoch 37/1000\n",
      "loss: 0.21207678070487945\n",
      "test_loss: 0.6234449489336265\n",
      "--------------------\n",
      "Epoch 38/1000\n",
      "loss: 0.1798437920546061\n",
      "test_loss: 0.4343713893832868\n",
      "--------------------\n",
      "Epoch 39/1000\n",
      "loss: 0.1872341395764236\n",
      "test_loss: 0.4473176101189956\n",
      "--------------------\n",
      "Epoch 40/1000\n",
      "loss: 0.1868935448378978\n",
      "test_loss: 0.37678904243205724\n",
      "--------------------\n",
      "Epoch 41/1000\n",
      "loss: 0.14291352837493546\n",
      "test_loss: 0.46715212149316804\n",
      "--------------------\n",
      "Epoch 42/1000\n",
      "loss: 0.15051508506171798\n",
      "test_loss: 0.37892493203674493\n",
      "--------------------\n",
      "Epoch 43/1000\n",
      "loss: 0.15171247601035265\n",
      "test_loss: 0.3942046526231264\n",
      "--------------------\n",
      "Epoch 44/1000\n",
      "loss: 0.15624484984334885\n",
      "test_loss: 0.3251355717187388\n",
      "--------------------\n",
      "Epoch 45/1000\n",
      "loss: 0.1445887308249152\n",
      "test_loss: 0.3644971220116866\n",
      "--------------------\n",
      "Epoch 46/1000\n",
      "loss: 0.1337315934391594\n",
      "test_loss: 0.2945262736134362\n",
      "--------------------\n",
      "Epoch 47/1000\n",
      "loss: 0.12865054661310033\n",
      "test_loss: 0.3074032691748519\n",
      "--------------------\n",
      "Epoch 48/1000\n",
      "loss: 0.1186922163776073\n",
      "test_loss: 0.28690036350305664\n",
      "--------------------\n",
      "Epoch 49/1000\n",
      "loss: 0.12982142030816982\n",
      "test_loss: 0.24846632020515308\n",
      "--------------------\n",
      "Epoch 50/1000\n",
      "loss: 0.11130141908825751\n",
      "test_loss: 0.26654110634862854\n",
      "--------------------\n",
      "Epoch 51/1000\n",
      "loss: 0.12373980216420534\n",
      "test_loss: 0.22088252542246328\n",
      "--------------------\n",
      "Epoch 52/1000\n",
      "loss: 0.10527526466339304\n",
      "test_loss: 0.21770350695506\n",
      "--------------------\n",
      "Epoch 53/1000\n",
      "loss: 0.1020326775972519\n",
      "test_loss: 0.19087631395903595\n",
      "--------------------\n",
      "Epoch 54/1000\n",
      "loss: 0.10903685345731087\n",
      "test_loss: 0.2350967283965203\n",
      "--------------------\n",
      "Epoch 55/1000\n",
      "loss: 0.09128911687436987\n",
      "test_loss: 0.19595223797583267\n",
      "--------------------\n",
      "Epoch 56/1000\n",
      "loss: 0.10805938832090121\n",
      "test_loss: 0.17965529443238648\n",
      "--------------------\n",
      "Epoch 57/1000\n",
      "loss: 0.10313175751198606\n",
      "test_loss: 0.18713951502975665\n",
      "--------------------\n",
      "Epoch 58/1000\n",
      "loss: 0.09188321955183423\n",
      "test_loss: 0.2657644671894479\n",
      "--------------------\n",
      "Epoch 59/1000\n",
      "loss: 0.08717434763757251\n",
      "test_loss: 0.20663317002503104\n",
      "--------------------\n",
      "Epoch 60/1000\n",
      "loss: 0.09151321107198958\n",
      "test_loss: 0.22948488242017398\n",
      "--------------------\n",
      "Epoch 61/1000\n",
      "loss: 0.0653725013569847\n",
      "test_loss: 0.18654135132224806\n",
      "--------------------\n",
      "Epoch 62/1000\n",
      "loss: 0.07694625820793015\n",
      "test_loss: 0.13916097228055851\n",
      "--------------------\n",
      "Epoch 63/1000\n",
      "loss: 0.06440609082755257\n",
      "test_loss: 0.16187837395179822\n",
      "--------------------\n",
      "Epoch 64/1000\n",
      "loss: 0.06381690404745505\n",
      "test_loss: 0.1776485797079084\n",
      "--------------------\n",
      "Epoch 65/1000\n",
      "loss: 0.05195511654305288\n",
      "test_loss: 0.1543520580478862\n",
      "--------------------\n",
      "Epoch 66/1000\n",
      "loss: 0.05515254097949844\n",
      "test_loss: 0.11882368267897778\n",
      "--------------------\n",
      "Epoch 67/1000\n",
      "loss: 0.055732253570264824\n",
      "test_loss: 0.17430212419161475\n",
      "--------------------\n",
      "Epoch 68/1000\n",
      "loss: 0.06440379150444642\n",
      "test_loss: 0.1192243818373403\n",
      "--------------------\n",
      "Epoch 69/1000\n",
      "loss: 0.0530995609256104\n",
      "test_loss: 0.128582765634188\n",
      "--------------------\n",
      "Epoch 70/1000\n",
      "loss: 0.05951892356071703\n",
      "test_loss: 0.16845071743642748\n",
      "--------------------\n",
      "Epoch 71/1000\n",
      "loss: 0.07533417657434352\n",
      "test_loss: 0.23875430446902388\n",
      "--------------------\n",
      "Epoch 72/1000\n",
      "loss: 0.07025144130845244\n",
      "test_loss: 0.22039882653686954\n",
      "--------------------\n",
      "Epoch 73/1000\n",
      "loss: 0.07475437142165263\n",
      "test_loss: 0.22760526481770763\n",
      "--------------------\n",
      "Epoch 74/1000\n",
      "loss: 0.0829573410257836\n",
      "test_loss: 0.2387752175992845\n",
      "--------------------\n",
      "Epoch 75/1000\n",
      "loss: 0.08642656342259183\n",
      "test_loss: 0.1814898509989705\n",
      "--------------------\n",
      "Epoch 76/1000\n",
      "loss: 0.07057945736226413\n",
      "test_loss: 0.16289558857189199\n",
      "--------------------\n",
      "Epoch 77/1000\n",
      "loss: 0.06909286910402507\n",
      "test_loss: 0.16024182633937975\n",
      "--------------------\n",
      "Epoch 78/1000\n",
      "loss: 0.07158315233455301\n",
      "test_loss: 0.15601072209609443\n",
      "--------------------\n",
      "Epoch 79/1000\n",
      "loss: 0.07371908008415055\n",
      "test_loss: 0.18612577722064758\n",
      "--------------------\n",
      "Epoch 80/1000\n",
      "loss: 0.08933173631687583\n",
      "test_loss: 0.15930984369193188\n",
      "--------------------\n",
      "Epoch 81/1000\n",
      "loss: 0.09792452437186352\n",
      "test_loss: 0.1294593906883771\n",
      "--------------------\n",
      "Epoch 82/1000\n",
      "loss: 0.10271164603743768\n",
      "test_loss: 0.16684235727389982\n",
      "--------------------\n",
      "Epoch 83/1000\n",
      "loss: 0.08359467185086064\n",
      "test_loss: 0.20126280412200445\n",
      "--------------------\n",
      "Epoch 84/1000\n",
      "loss: 0.08306695638161168\n",
      "test_loss: 0.17172301413180927\n",
      "--------------------\n",
      "Epoch 85/1000\n",
      "loss: 0.09380371165829465\n",
      "test_loss: 0.18815949078641114\n",
      "--------------------\n",
      "Epoch 86/1000\n",
      "loss: 0.11892061448337413\n",
      "test_loss: 0.28006217692541613\n",
      "--------------------\n",
      "Epoch 87/1000\n",
      "loss: 0.16555132246331164\n",
      "test_loss: 0.32131565020934333\n",
      "--------------------\n",
      "Epoch 88/1000\n",
      "loss: 0.18467900852198926\n",
      "test_loss: 0.46171925021560145\n",
      "--------------------\n",
      "Epoch 89/1000\n",
      "loss: 0.26136838268129187\n",
      "test_loss: 0.5125932765827441\n",
      "--------------------\n",
      "Epoch 90/1000\n",
      "loss: 0.27374731263006924\n",
      "test_loss: 0.5382207708000287\n",
      "--------------------\n",
      "Epoch 91/1000\n",
      "loss: 0.280270001019776\n",
      "test_loss: 0.5259744719961625\n",
      "--------------------\n",
      "Epoch 92/1000\n",
      "loss: 0.2941218954408868\n",
      "test_loss: 0.4800700708945984\n",
      "--------------------\n",
      "Epoch 93/1000\n",
      "loss: 0.3059964842702213\n",
      "test_loss: 0.4950780869204257\n",
      "--------------------\n",
      "Epoch 94/1000\n",
      "loss: 0.3060001367948165\n",
      "test_loss: 0.4423632476838273\n",
      "--------------------\n",
      "Epoch 95/1000\n",
      "loss: 0.327463805344642\n",
      "test_loss: 0.4528435587948352\n",
      "--------------------\n",
      "Epoch 96/1000\n",
      "loss: 0.30109730821609365\n",
      "test_loss: 0.4983803345576713\n",
      "--------------------\n",
      "Epoch 97/1000\n",
      "loss: 0.30588469621439446\n",
      "test_loss: 0.5651381357344227\n",
      "--------------------\n",
      "Epoch 98/1000\n",
      "loss: 0.31771606412765224\n",
      "test_loss: 0.6007426662141817\n",
      "--------------------\n",
      "Epoch 99/1000\n",
      "loss: 0.30969470624378964\n",
      "test_loss: 0.6715626893401668\n",
      "--------------------\n",
      "Epoch 100/1000\n",
      "loss: 0.31551139612208334\n",
      "test_loss: 0.7359745272092129\n",
      "--------------------\n",
      "Epoch 101/1000\n",
      "loss: 0.3157019178677154\n",
      "test_loss: 0.7202229179981116\n",
      "--------------------\n",
      "Epoch 102/1000\n",
      "loss: 0.3292022338872285\n",
      "test_loss: 0.6414894750913638\n",
      "--------------------\n",
      "Epoch 103/1000\n",
      "loss: 0.27570919003827793\n",
      "test_loss: 0.5842813567764926\n",
      "--------------------\n",
      "Epoch 104/1000\n",
      "loss: 0.2419559211805136\n",
      "test_loss: 0.555100434312695\n",
      "--------------------\n",
      "Epoch 105/1000\n",
      "loss: 0.2472068597644306\n",
      "test_loss: 0.5512316601775717\n",
      "--------------------\n",
      "Epoch 106/1000\n",
      "loss: 0.24326207298017516\n",
      "test_loss: 0.5261588554110443\n",
      "--------------------\n",
      "Epoch 107/1000\n",
      "loss: 0.26635055781521816\n",
      "test_loss: 0.4779426417427889\n",
      "--------------------\n",
      "Epoch 108/1000\n",
      "loss: 0.25562174934403675\n",
      "test_loss: 0.48369873769319893\n",
      "--------------------\n",
      "Epoch 109/1000\n",
      "loss: 0.26360809947609115\n",
      "test_loss: 0.5041573458726991\n",
      "--------------------\n",
      "Epoch 110/1000\n",
      "loss: 0.26359883760379854\n",
      "test_loss: 0.5233683501811404\n",
      "--------------------\n",
      "Epoch 111/1000\n",
      "loss: 0.2496042212700112\n",
      "test_loss: 0.5264271331068716\n",
      "--------------------\n",
      "Epoch 112/1000\n",
      "loss: 0.2606645803980268\n",
      "test_loss: 0.5152743525410953\n",
      "--------------------\n",
      "Epoch 113/1000\n",
      "loss: 0.25204520256323903\n",
      "test_loss: 0.48428892540304286\n",
      "--------------------\n",
      "Epoch 114/1000\n",
      "loss: 0.24693397479948767\n",
      "test_loss: 0.47319357760511993\n",
      "--------------------\n",
      "Epoch 115/1000\n",
      "loss: 0.24981683935447221\n",
      "test_loss: 0.4752632053732349\n",
      "--------------------\n",
      "Epoch 116/1000\n",
      "loss: 0.2661985774083357\n",
      "test_loss: 0.46835792028720963\n",
      "--------------------\n",
      "Epoch 117/1000\n",
      "loss: 0.2550504606282502\n",
      "test_loss: 0.4969836051918958\n",
      "--------------------\n",
      "Epoch 118/1000\n",
      "loss: 0.25981246565648336\n",
      "test_loss: 0.5005920911697965\n",
      "--------------------\n",
      "Epoch 119/1000\n",
      "loss: 0.25067299124457987\n",
      "test_loss: 0.5017896128262866\n",
      "--------------------\n",
      "Epoch 120/1000\n",
      "loss: 0.24218032464156286\n",
      "test_loss: 0.4879568677983786\n",
      "--------------------\n",
      "Epoch 121/1000\n",
      "loss: 0.24624359957350975\n",
      "test_loss: 0.47040014576755074\n",
      "--------------------\n",
      "Epoch 122/1000\n",
      "loss: 0.2488170172529001\n",
      "test_loss: 0.49704956681581963\n",
      "--------------------\n",
      "Epoch 123/1000\n",
      "loss: 0.23641759710255683\n",
      "test_loss: 0.5297155283522188\n",
      "--------------------\n",
      "Epoch 124/1000\n",
      "loss: 0.22599974302820078\n",
      "test_loss: 0.5330954171847879\n",
      "--------------------\n",
      "Epoch 125/1000\n",
      "loss: 0.23230611383833252\n",
      "test_loss: 0.5284067447901818\n",
      "--------------------\n",
      "Epoch 126/1000\n",
      "loss: 0.25211457152883604\n",
      "test_loss: 0.5238299027346728\n",
      "--------------------\n",
      "Epoch 127/1000\n",
      "loss: 0.23825303175110826\n",
      "test_loss: 0.5575615121868619\n",
      "--------------------\n",
      "Epoch 128/1000\n",
      "loss: 0.23298853794276192\n",
      "test_loss: 0.5872461087021389\n",
      "--------------------\n",
      "Epoch 129/1000\n",
      "loss: 0.2556259651063827\n",
      "test_loss: 0.5949746024909249\n",
      "--------------------\n",
      "Epoch 130/1000\n",
      "loss: 0.27035168404772614\n",
      "test_loss: 0.5804628984054976\n",
      "--------------------\n",
      "Epoch 131/1000\n",
      "loss: 0.2711083771611907\n",
      "test_loss: 0.5736389799991197\n",
      "--------------------\n",
      "Epoch 132/1000\n",
      "loss: 0.27394525794181646\n",
      "test_loss: 0.6062910883573064\n",
      "--------------------\n",
      "Epoch 133/1000\n",
      "loss: 0.29154791254877\n",
      "test_loss: 0.7240857097663378\n",
      "--------------------\n",
      "Epoch 134/1000\n",
      "loss: 0.31338760955259204\n",
      "test_loss: 0.781627965731579\n",
      "--------------------\n",
      "Epoch 135/1000\n",
      "loss: 0.40103443914599585\n",
      "test_loss: 0.7534240612335372\n",
      "--------------------\n",
      "Epoch 136/1000\n",
      "loss: 0.4395487455471435\n",
      "test_loss: 0.697920328659708\n",
      "--------------------\n",
      "Epoch 137/1000\n",
      "loss: 0.440599145004199\n",
      "test_loss: 0.7055273497509852\n",
      "--------------------\n",
      "Epoch 138/1000\n",
      "loss: 0.43532774248568895\n",
      "test_loss: 0.7064336855618054\n",
      "--------------------\n",
      "Epoch 139/1000\n",
      "loss: 0.45859119398192616\n",
      "test_loss: 0.7445882618296564\n",
      "--------------------\n",
      "Epoch 140/1000\n",
      "loss: 0.4290699454661655\n",
      "test_loss: 0.7262686001169577\n",
      "--------------------\n",
      "Epoch 141/1000\n",
      "loss: 0.4148771512575382\n",
      "test_loss: 0.7383304595489774\n",
      "--------------------\n",
      "Epoch 142/1000\n",
      "loss: 0.4395509648234828\n",
      "test_loss: 0.6999207869041384\n",
      "--------------------\n",
      "Epoch 143/1000\n",
      "loss: 0.46614319711858243\n",
      "test_loss: 0.6959886883238429\n",
      "--------------------\n",
      "Epoch 144/1000\n",
      "loss: 0.5098224759526682\n",
      "test_loss: 0.7020801596931721\n",
      "--------------------\n",
      "Epoch 145/1000\n",
      "loss: 0.552107992292006\n",
      "test_loss: 0.7541617857324973\n",
      "--------------------\n",
      "Epoch 146/1000\n",
      "loss: 0.6143212038941943\n",
      "test_loss: 0.754785641864465\n",
      "--------------------\n",
      "Epoch 147/1000\n",
      "loss: 0.668609789981131\n",
      "test_loss: 0.8629511495104485\n",
      "--------------------\n",
      "Epoch 148/1000\n",
      "loss: 0.6944440498359894\n",
      "test_loss: 1.0005899625258488\n",
      "--------------------\n",
      "Epoch 149/1000\n",
      "loss: 0.8041832959442808\n",
      "test_loss: 1.0441524886379117\n",
      "--------------------\n",
      "Epoch 150/1000\n",
      "loss: 0.7621479318395519\n",
      "test_loss: 0.99752986038986\n",
      "--------------------\n",
      "Epoch 151/1000\n",
      "loss: 0.774251773626658\n",
      "test_loss: 1.035051072882325\n",
      "--------------------\n",
      "Epoch 152/1000\n",
      "loss: 0.7934913476765678\n",
      "test_loss: 1.0005440031782837\n",
      "--------------------\n",
      "Epoch 153/1000\n",
      "loss: 0.7636214009437122\n",
      "test_loss: 1.154677260691594\n",
      "--------------------\n",
      "Epoch 154/1000\n",
      "loss: 0.7345297106852134\n",
      "test_loss: 1.2544295758401092\n",
      "--------------------\n",
      "Epoch 155/1000\n",
      "loss: 0.7577502375730035\n",
      "test_loss: 1.2774138091818283\n",
      "--------------------\n",
      "Epoch 156/1000\n",
      "loss: 0.8371474785370785\n",
      "test_loss: 1.1500474814358248\n",
      "--------------------\n",
      "Epoch 157/1000\n",
      "loss: 0.8822881539041797\n",
      "test_loss: 1.0185515987768508\n",
      "--------------------\n",
      "Epoch 158/1000\n",
      "loss: 0.9747396141225309\n",
      "test_loss: 0.8712683033786321\n",
      "--------------------\n",
      "Epoch 159/1000\n",
      "loss: 1.0892779201661285\n",
      "test_loss: 0.8401680377622446\n",
      "--------------------\n",
      "Epoch 160/1000\n",
      "loss: 1.1190963137829513\n",
      "test_loss: 0.8584367682536443\n",
      "--------------------\n",
      "Epoch 161/1000\n",
      "loss: 1.2204063375268066\n",
      "test_loss: 0.8637169219161335\n",
      "--------------------\n",
      "Epoch 162/1000\n",
      "loss: 1.3089295270150167\n",
      "test_loss: 0.88113120211321\n",
      "--------------------\n",
      "Epoch 163/1000\n",
      "loss: 1.3524500782552518\n",
      "test_loss: 0.9317342340619418\n",
      "--------------------\n",
      "Epoch 164/1000\n",
      "loss: 1.3233680381325252\n",
      "test_loss: 0.9998263377663598\n",
      "--------------------\n",
      "Epoch 165/1000\n",
      "loss: 1.2709962413237805\n",
      "test_loss: 1.0639803058042991\n",
      "--------------------\n",
      "Epoch 166/1000\n",
      "loss: 1.1991943183698153\n",
      "test_loss: 1.0757994573612355\n",
      "--------------------\n",
      "Epoch 167/1000\n",
      "loss: 1.1391180839977766\n",
      "test_loss: 1.0760923546918653\n",
      "--------------------\n",
      "Epoch 168/1000\n",
      "loss: 1.1556163462891913\n",
      "test_loss: 1.0691176473996358\n",
      "--------------------\n",
      "Epoch 169/1000\n",
      "loss: 1.136780643280138\n",
      "test_loss: 1.082307151910898\n",
      "--------------------\n",
      "Epoch 170/1000\n",
      "loss: 1.1612747199833393\n",
      "test_loss: 1.0620822380705361\n",
      "--------------------\n",
      "Epoch 171/1000\n",
      "loss: 1.131958938546871\n",
      "test_loss: 1.0679353873588537\n",
      "--------------------\n",
      "Epoch 172/1000\n",
      "loss: 1.1362589250335045\n",
      "test_loss: 1.0901502761336272\n",
      "--------------------\n",
      "Epoch 173/1000\n"
     ]
    }
   ],
   "source": [
    "# 使用する人物のID\n",
    "person_id = \"Person1201\"\n",
    "# データが格納されているディレクトリ\n",
    "path = \"./data/HASC-BasicActivity\"\n",
    "# 1つの入力データの長さ\n",
    "sequence_length = 15\n",
    "# 入力データの次元\n",
    "input_dim = 3\n",
    "# 出力データの次元\n",
    "output_dim = 6\n",
    "# 隠れ層の次元\n",
    "hidden_dim = 128\n",
    "# テストデータの割合\n",
    "test_size = 0.2\n",
    "# 訓練パラメータ\n",
    "lr = 0.0001\n",
    "# CUDA を使用するか\n",
    "benchmark = True\n",
    "# epoch 数\n",
    "epoch_num = 1000\n",
    "# バッチサイズ(データセットを分割した数)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# データセットを作成\n",
    "train = Train(input_dim, output_dim, hidden_dim, True, lr, benchmark)\n",
    "inputs, labels, _ = train.make_dataset(sequence_length, person_id, path)\n",
    "labels_index = train.labels2int(labels)\n",
    "# 訓練データとテストデータに分割\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels_index, test_size=test_size, shuffle=False)\n",
    "# 訓練する\n",
    "train.train(train_inputs, train_labels, test_inputs, test_labels, epoch_num, batch_size, sequence_length)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
