{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from persor import BVHparser\n",
    "from scipy.spatial.transform import Rotation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint_coords(skeleton, joint, coords):\n",
    "    offset = skeleton[joint][\"offset\"]\n",
    "    parent_joint = skeleton[joint][\"joint\"]\n",
    "    child_joints = skeleton[joint][\"children\"]\n",
    "\n",
    "    if parent_joint == None:\n",
    "        return\n",
    "\n",
    "    parent_coord = coords[parent_joint][\"coord\"]\n",
    "\n",
    "    current_coord = [\n",
    "        parent_coord[0] + offset[0],\n",
    "        parent_coord[1] + offset[1],\n",
    "        parent_coord[2] + offset[2],\n",
    "    ]\n",
    "    coords[joint] = {\"coord\": current_coord, \"parent\": parent_joint}\n",
    "\n",
    "    for child in child_joints:\n",
    "        get_joint_coords(skeleton, child, coords)\n",
    "\n",
    "\n",
    "def skelton2coords(skeleton):\n",
    "    coords = {\"root\": {\"coord\": skeleton[\"root\"][\"offset\"], \"parent\": None}}\n",
    "    skeleton[\"root\"]\n",
    "\n",
    "    child_joints = skeleton[\"root\"][\"children\"]\n",
    "    for child in child_joints:\n",
    "        get_joint_coords(skeleton, child, coords)\n",
    "\n",
    "    get_joint_coords(skeleton, \"root\", coords)\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "def rotated_offset(skeleton, frame):\n",
    "    skeleton_copy = copy.deepcopy(skeleton)\n",
    "    for joint, data in skeleton_copy.items():\n",
    "        if joint == \"root\" or joint.startswith(\"_\"):\n",
    "            continue\n",
    "\n",
    "        x_rotate = np.deg2rad(frame[f\"{joint}_Xrotation\"])\n",
    "        y_rotate = np.deg2rad(frame[f\"{joint}_Yrotation\"])\n",
    "        z_rotate = np.deg2rad(frame[f\"{joint}_Zrotation\"])\n",
    "\n",
    "        rot = Rotation.from_rotvec(np.array([y_rotate, x_rotate, z_rotate]))\n",
    "        skeleton_copy[joint][\"offset\"] = rot.apply(data[\"offset\"])\n",
    "\n",
    "    return skeleton_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bvhp = BVHparser(\"./data/jump.bvh\")\n",
    "skeleton = bvhp.get_skeleton()\n",
    "motion_df = bvhp.get_motion_df()\n",
    "motion_frame = motion_df.iloc[800, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_skeleton = rotated_offset(skeleton, motion_frame)\n",
    "rotated_coord = skelton2coords(rotated_skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ST-GCNするよ\n",
    "\n",
    "https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/03_action_recognition_ST_GCN.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from persor import BVHparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Use CUDA:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現性を担保\n",
    "\n",
    "seed = 123\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隣接行列を作成\n",
    "class Graph:\n",
    "    def __init__(self, hop_size, bvhp):\n",
    "        skeleton = bvhp.get_skeleton()\n",
    "        node_num = len(skeleton)\n",
    "        self.edge = self.__get_edge(bvhp)\n",
    "\n",
    "        # hop数分離れた関節を取得\n",
    "        hop_dis = self.__get_hop_distance(self.node_num, self.edge, hop_size)\n",
    "\n",
    "        # 隣接行列を作成\n",
    "        self.A = self.__get_adjacency_mat(hop_dis, hop_size)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.A\n",
    "\n",
    "    def __get_edge(self, skeleton):\n",
    "        edge = []\n",
    "        for joint, data in skeleton.items():\n",
    "            print(joint, data)\n",
    "            parent_id = data[\"id\"]\n",
    "            children = data[\"children\"]\n",
    "            children_ids = [skeleton[child][\"id\"] for child in children]\n",
    "            edge.extend([(parent_id, child_id) for child_id in children_ids])\n",
    "            edge.extend([(child_id, parent_id) for child_id in children_ids])\n",
    "            edge.append((parent_id, parent_id))\n",
    "\n",
    "        return edge\n",
    "\n",
    "    def __get_hop_distance(self, node_num, edge, hop_size):\n",
    "        A = np.zeros((node_num, node_num))\n",
    "\n",
    "        for i, j in edge:\n",
    "            A[j, i] = 1\n",
    "            A[i, j] = 1\n",
    "\n",
    "        hop_dis = np.zeros((node_num, node_num)) + np.inf\n",
    "        transfer_mat = [np.linalg.matrix_power(A, d) for d in range(hop_size + 1)]\n",
    "        arrive_mat = np.stack(transfer_mat) > 0\n",
    "\n",
    "        [hop_dis[arrive_mat[d]] for d in range(hop_size + 1)]\n",
    "\n",
    "        return hop_dis\n",
    "\n",
    "    def __get_adjacency_mat(self, hop_dis, hop_size):\n",
    "        valid_hop = range(0, hop_size + 1, 1)\n",
    "        adjacency = np.where(np.isin(hop_dis, valid_hop), 1, 0)\n",
    "\n",
    "        normalize_adjacency = self.__normalize_digraph(adjacency)\n",
    "        A = np.array(\n",
    "            [np.where(hop_dis == hop, normalize_adjacency, 0) for hop in valid_hop]\n",
    "        )\n",
    "\n",
    "        return A\n",
    "\n",
    "    def __normalize_digraph(self, A):\n",
    "        Dl = np.sum(A, axis=0)\n",
    "        node_num = A.shape[0]\n",
    "        Dn = np.diag([Dl[i] ** (-1) if Dl[i] > 0 else 0 for i in range(node_num)])\n",
    "        DAD = np.dot(A, Dn)\n",
    "\n",
    "        return DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何者?\n",
    "class STGC_block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, stride, t_kernel_size, A_size, dropout=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # 空間グラフの畳み込み\n",
    "        self.sgc = SpatialGraphConvolution(\n",
    "            in_channels=in_channels, out_channels=out_channels, s_kernel_size=A_size[0]\n",
    "        )\n",
    "\n",
    "        # Learnable weight matrix M エッジに重みを与えます. どのエッジが重要かを学習します.\n",
    "        self.M = nn.Parameter(torch.ones(A_size))\n",
    "\n",
    "        self.tgc = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                (t_kernel_size, 1),\n",
    "                (stride, 1),\n",
    "                ((t_kernel_size - 1) // 2, 0),\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.tgc(self.sgc(x, A * self.M))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを定義\n",
    "class ST_GCN(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels, t_kernel_size, hop_size, bvhp):\n",
    "        super().__init__()\n",
    "        # グラフ作成\n",
    "        graph = Graph(hop_size, bvhp)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer(\"A\", A)\n",
    "        A_size = A.size()\n",
    "\n",
    "        # バッチ正規化\n",
    "        self.bn = nn.BatchNorm1d(in_channels * A_size[1])\n",
    "\n",
    "        # STGC_block\n",
    "        self.stgc1 = STGC_block(in_channels, 32, 1, t_kernel_size, A_size)\n",
    "        self.stgc2 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n",
    "        self.stgc3 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n",
    "        self.stgc4 = STGC_block(32, 64, 2, t_kernel_size, A_size)\n",
    "        self.stgc5 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n",
    "        self.stgc6 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n",
    "\n",
    "        # 予測\n",
    "        self.fc = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Batch Normalization\n",
    "        N, C, T, V = x.size()  # batch, channel, frame, node\n",
    "        x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n",
    "        x = self.bn(x)\n",
    "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        # STGC_blocks\n",
    "        x = self.stgc1(x, self.A)\n",
    "        x = self.stgc2(x, self.A)\n",
    "        x = self.stgc3(x, self.A)\n",
    "        x = self.stgc4(x, self.A)\n",
    "        x = self.stgc5(x, self.A)\n",
    "        x = self.stgc6(x, self.A)\n",
    "\n",
    "        # Prediction\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(N, -1, 1, 1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの定義\n",
    "class Feeder(torch.utils.data.Dataset):\n",
    "    def __init__(self, bvh_path, label_path):\n",
    "        super().__init__()\n",
    "        self.motion_df = self.__load_bvh(bvh_path)\n",
    "        self.label_df = self.__load_label(label_path)\n",
    "\n",
    "    def __load_bvh(self, bvh_path):\n",
    "        bvhp = BVHparser(bvh_path)\n",
    "        motion_df = bvhp.get_motion_df()\n",
    "        return motion_df\n",
    "\n",
    "    def __load_label(self, label_path):\n",
    "        label_df = pd.read_csv(label_path, header=None, names=[\"start\", \"end\", \"label\"])\n",
    "        return label_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = np.array(self.data[index])\n",
    "        label = self.label[index]\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポック数とバッチサイズ\n",
    "NUM_EPOCH = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "bvhp = BVHparser(\"./_data/jump.bvh\")\n",
    "\n",
    "# モデルを作成\n",
    "model = ST_GCN(\n",
    "    num_classes=10,\n",
    "    in_channels=3,\n",
    "    t_kernel_size=9,  # 時間グラフ畳み込みのカーネルサイズ (t_kernel_size × 1)\n",
    "    hop_size=2,\n",
    "    bvhp=bvhp,\n",
    ")\n",
    "\n",
    "# オプティマイザ\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# 誤差関数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# データセットの用意\n",
    "data_loader = dict()\n",
    "data_loader[\"train\"] = torch.utils.data.DataLoader(\n",
    "    dataset=Feeder(data_path=\"data/train_data.npy\", label_path=\"data/train_label.npy\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "data_loader[\"test\"] = torch.utils.data.DataLoader(\n",
    "    dataset=Feeder(data_path=\"data/test_data.npy\", label_path=\"data/test_label.npy\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# モデルを学習モードに変更\n",
    "model.train()\n",
    "\n",
    "# 学習開始\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    correct = 0\n",
    "    sum_loss = 0\n",
    "    for batch_idx, (data, label) in enumerate(data_loader[\"train\"]):\n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        _, predict = torch.max(output.data, 1)\n",
    "        correct += (predict == label).sum().item()\n",
    "\n",
    "    print(\n",
    "        \"# Epoch: {} | Loss: {:.4f} | Accuracy: {:.4f}\".format(\n",
    "            epoch,\n",
    "            sum_loss / len(data_loader[\"train\"].dataset),\n",
    "            (100.0 * correct / len(data_loader[\"train\"].dataset)),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
