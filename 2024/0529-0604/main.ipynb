{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ST-GCNするよ\n",
    "\n",
    "<https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/03_action_recognition_ST_GCN.ipynb>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from persor import BVHparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use CUDA: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Use CUDA:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現性を担保\n",
    "\n",
    "seed = 123\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隣接行列を作成\n",
    "class Graph:\n",
    "    def __init__(self, hop_size, skeleton):\n",
    "        self.node_num = len(skeleton)\n",
    "        self.edge = self.__get_edge(skeleton)\n",
    "\n",
    "        # hop数分離れた関節を取得\n",
    "        hop_dis = self.__get_hop_distance(self.node_num, self.edge, hop_size)\n",
    "\n",
    "        # 隣接行列を作成\n",
    "        self.A = self.__get_adjacency_mat(hop_dis, hop_size)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.A\n",
    "\n",
    "    def __get_edge(self, skeleton):\n",
    "        edge = []\n",
    "        for _, data in skeleton.items():\n",
    "            parent_id = data[\"id\"]\n",
    "            children = data[\"children\"]\n",
    "            children_ids = [skeleton[child][\"id\"] for child in children]\n",
    "            edge.extend([(parent_id, child_id) for child_id in children_ids])\n",
    "            edge.extend([(child_id, parent_id) for child_id in children_ids])\n",
    "            edge.append((parent_id, parent_id))\n",
    "\n",
    "        return edge\n",
    "\n",
    "    def __get_hop_distance(self, node_num, edge, hop_size):\n",
    "        A = np.zeros((node_num, node_num))\n",
    "\n",
    "        for i, j in edge:\n",
    "            A[j, i] = 1\n",
    "            A[i, j] = 1\n",
    "\n",
    "        hop_dis = np.zeros((node_num, node_num)) + np.inf\n",
    "        transfer_mat = [np.linalg.matrix_power(\n",
    "            A, d) for d in range(hop_size + 1)]\n",
    "        arrive_mat = np.stack(transfer_mat) > 0\n",
    "\n",
    "        [hop_dis[arrive_mat[d]] for d in range(hop_size + 1)]\n",
    "\n",
    "        return hop_dis\n",
    "\n",
    "    def __get_adjacency_mat(self, hop_dis, hop_size):\n",
    "        valid_hop = range(0, hop_size + 1, 1)\n",
    "        adjacency = np.where(np.isin(hop_dis, valid_hop), 1, 0)\n",
    "\n",
    "        normalize_adjacency = self.__normalize_digraph(adjacency)\n",
    "        A = np.array(\n",
    "            [np.where(hop_dis == hop, normalize_adjacency, 0)\n",
    "             for hop in valid_hop]\n",
    "        )\n",
    "\n",
    "        return A\n",
    "\n",
    "    def __normalize_digraph(self, A):\n",
    "        Dl = np.sum(A, axis=0)\n",
    "        node_num = A.shape[0]\n",
    "        Dn = np.diag([Dl[i] ** (-1) if Dl[i] >\n",
    "                     0 else 0 for i in range(node_num)])\n",
    "        DAD = np.dot(A, Dn)\n",
    "\n",
    "        return DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空間畳み込みグラフ\n",
    "class SpatialGraphConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, s_kernel_size):\n",
    "        super().__init__()\n",
    "        self.s_kernel_size = s_kernel_size\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels * s_kernel_size,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.s_kernel_size, kc // self.s_kernel_size, t, v)\n",
    "        # 隣接行列にGCを行い, 特徴を足し合わせています.\n",
    "        x = torch.einsum(\"nkctv,kvw->nctw\", (x, A))\n",
    "        return x.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 何者?\n",
    "class STGC_block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, stride, t_kernel_size, A_size, dropout=0.5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # 空間グラフの畳み込み\n",
    "        self.sgc = SpatialGraphConvolution(\n",
    "            in_channels=in_channels, out_channels=out_channels, s_kernel_size=A_size[0]\n",
    "        )\n",
    "\n",
    "        # Learnable weight matrix M エッジに重みを与えます. どのエッジが重要かを学習します.\n",
    "        self.M = nn.Parameter(torch.ones(A_size))\n",
    "\n",
    "        self.tgc = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                (t_kernel_size, 1),\n",
    "                (stride, 1),\n",
    "                ((t_kernel_size - 1) // 2, 0),\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.tgc(self.sgc(x, A * self.M))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを定義\n",
    "class ST_GCN(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels, t_kernel_size, hop_size, skeleton):\n",
    "        super().__init__()\n",
    "        # グラフ作成\n",
    "        graph = Graph(hop_size, skeleton)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer(\"A\", A)\n",
    "        A_size = A.size()\n",
    "\n",
    "        # バッチ正規化\n",
    "        self.bn = nn.BatchNorm1d(in_channels * A_size[1])\n",
    "\n",
    "        # STGC_block\n",
    "        self.stgc1 = STGC_block(in_channels, 32, 1, t_kernel_size, A_size)\n",
    "        self.stgc2 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n",
    "        self.stgc3 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n",
    "        self.stgc4 = STGC_block(32, 64, 2, t_kernel_size, A_size)\n",
    "        self.stgc5 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n",
    "        self.stgc6 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n",
    "\n",
    "        # 予測\n",
    "        self.fc = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Batch Normalization\n",
    "        N, C, T, V = x.size()  # batch, channel, frame, node\n",
    "        x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n",
    "        x = self.bn(x)\n",
    "        x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        # STGC_blocks\n",
    "        x = self.stgc1(x, self.A)\n",
    "        x = self.stgc2(x, self.A)\n",
    "        x = self.stgc3(x, self.A)\n",
    "        x = self.stgc4(x, self.A)\n",
    "        x = self.stgc5(x, self.A)\n",
    "        x = self.stgc6(x, self.A)\n",
    "\n",
    "        # Prediction\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(N, -1, 1, 1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの定義\n",
    "class Feeder(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, label_path):\n",
    "        super().__init__()\n",
    "        self.data = np.load(data_path)\n",
    "        self.label = np.load(label_path)\n",
    "        print(self.data.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.label[index]\n",
    "\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21871, 27, 3)\n",
      "(7248, 27, 3)\n"
     ]
    }
   ],
   "source": [
    "# エポック数とバッチサイズ\n",
    "NUM_EPOCH = 100\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 骨格情報\n",
    "skeleton = BVHparser(\"data/bvh/all1.bvh\").get_skeleton()\n",
    "\n",
    "# モデルを作成\n",
    "model = ST_GCN(\n",
    "    num_classes=5,\n",
    "    in_channels=3,\n",
    "    t_kernel_size=9,  # 時間グラフ畳み込みのカーネルサイズ (t_kernel_size × 1)\n",
    "    hop_size=2,\n",
    "    skeleton=skeleton,\n",
    ")\n",
    "\n",
    "# オプティマイザ\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# 誤差関数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# データセットの用意\n",
    "train_data = torch.utils.data.DataLoader(\n",
    "    dataset=Feeder(data_path=\"data/train_data.npy\", label_path=\"data/train_label.npy\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_data = torch.utils.data.DataLoader(\n",
    "    dataset=Feeder(data_path=\"data/test_data.npy\", label_path=\"data/test_label.npy\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# モデルを学習モードに変更\n",
    "_ = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 27, 3])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# data = data.cuda()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# label = label.cuda()\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, label)\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36mST_GCN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Batch Normalization\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     N, C, T, V \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()  \u001b[38;5;66;03m# batch, channel, frame, node\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(N, V \u001b[38;5;241m*\u001b[39m C, T)\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "# 学習開始\n",
    "for epoch in range(1, NUM_EPOCH + 1):\n",
    "    correct = 0\n",
    "    sum_loss = 0\n",
    "    for batch_idx, (data, label) in enumerate(train_data):\n",
    "        print(data.shape)\n",
    "        # data = data.cuda()\n",
    "        # label = label.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sum_loss += loss.item()\n",
    "        _, predict = torch.max(output.data, 1)\n",
    "        correct += (predict == label).sum().item()\n",
    "\n",
    "    print(\n",
    "        \"# Epoch: {} | Loss: {:.4f} | Accuracy: {:.4f}\".format(\n",
    "            epoch,\n",
    "            sum_loss / len(train_data.dataset),\n",
    "            (100.0 * correct / len(train_data.dataset)),\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
