{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "# submodules\n",
    "from net.st_gcn import ST_GCN_Model\n",
    "from feeder.feeder import Feeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ST_GCN_Processor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data_path,\n",
    "        train_label_path,\n",
    "        test_data_path,\n",
    "        test_label_path,\n",
    "        in_channels=3,\n",
    "        num_class=60,\n",
    "        dropout=0.5,\n",
    "        edge_importance_weighting=True,\n",
    "        graph_args={\"layout\": \"ntu-rgb+d\", \"strategy\": \"spatial\"},\n",
    "        step=[10, 50],\n",
    "        base_lr=0.01,\n",
    "        batch_size=64,\n",
    "        test_batch_size=64,\n",
    "        epoch=80,\n",
    "        topk=5,\n",
    "        debug=False,\n",
    "        model_path=\"epoch_model.pt\",\n",
    "    ):\n",
    "        self.step = step\n",
    "        self.base_lr = base_lr\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.debug = debug\n",
    "        self.epoch = epoch\n",
    "        self.meta_info = dict(epoch=0, iter=1)\n",
    "        self.epoch_info = dict()\n",
    "        self.result = dict()\n",
    "        self.model_path = model_path\n",
    "        self.topk = topk\n",
    "        self.dev = (\n",
    "            torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        )\n",
    "        self.__load_model(\n",
    "            in_channels,\n",
    "            num_class,\n",
    "            dropout,\n",
    "            edge_importance_weighting,\n",
    "            graph_args,\n",
    "        )\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=self.base_lr,\n",
    "            momentum=0.9,\n",
    "            nesterov=True,\n",
    "            weight_decay=0.0001,\n",
    "        )\n",
    "\n",
    "        self.__load_data(\n",
    "            train_data_path,\n",
    "            train_label_path,\n",
    "            test_data_path,\n",
    "            test_label_path,\n",
    "        )\n",
    "\n",
    "    def __weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find(\"Conv1d\") != -1:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0)\n",
    "        elif classname.find(\"Conv2d\") != -1:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0)\n",
    "        elif classname.find(\"BatchNorm\") != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "    def __load_model(\n",
    "        self,\n",
    "        in_channels,\n",
    "        num_class,\n",
    "        dropout,\n",
    "        edge_importance_weighting,\n",
    "        graph_args,\n",
    "    ):\n",
    "        self.model = ST_GCN_Model(\n",
    "            in_channels=in_channels,\n",
    "            num_class=num_class,\n",
    "            dropout=dropout,\n",
    "            edge_importance_weighting=edge_importance_weighting,\n",
    "            graph_args=graph_args,\n",
    "        )\n",
    "        self.model.apply(self.__weights_init)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        # model_path が存在する場合は、そのモデルをロードする\n",
    "        if self.model_path != None and os.path.exists(self.model_path):\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(self.model_path, map_location=self.dev, weights_only=True)\n",
    "            )\n",
    "            print(f\"The model has been loaded from {self.model_path}.\")\n",
    "\n",
    "    def __adjust_lr(self):\n",
    "        if self.step:\n",
    "            lr = self.base_lr * (\n",
    "                0.1 ** np.sum(self.meta_info[\"epoch\"] >= np.array(self.step))\n",
    "            )\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "            self.lr = lr\n",
    "        else:\n",
    "            self.lr = self.base_lr\n",
    "\n",
    "    def __load_data(\n",
    "        self,\n",
    "        train_data_path,\n",
    "        train_label_path,\n",
    "        test_data_path,\n",
    "        test_label_path,\n",
    "        num_workers=11,\n",
    "    ):\n",
    "        self.data_loader = dict()\n",
    "        self.data_loader[\"train\"] = torch.utils.data.DataLoader(\n",
    "            dataset=Feeder(\n",
    "                data_path=train_data_path,\n",
    "                label_path=train_label_path,\n",
    "                debug=self.debug,\n",
    "            ),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=True,\n",
    "        )\n",
    "        self.data_loader[\"test\"] = torch.utils.data.DataLoader(\n",
    "            dataset=Feeder(\n",
    "                data_path=test_data_path,\n",
    "                label_path=test_label_path,\n",
    "                debug=self.debug,\n",
    "            ),\n",
    "            batch_size=self.test_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "\n",
    "    def __save_model(self, model):\n",
    "        state_dict = model.state_dict()\n",
    "        weights = OrderedDict(\n",
    "            [[\"\".join(k.split(\"module.\")), v.cpu()] for k, v in state_dict.items()]\n",
    "        )\n",
    "        torch.save(weights, self.model_path)\n",
    "        print(f\"The model has been saved as {self.model_path}.\")\n",
    "\n",
    "    def __show_topk(self, k):\n",
    "        rank = self.result.argsort()\n",
    "        hit_top_k = [l in rank[i, -k:] for i, l in enumerate(self.label)]\n",
    "        accuracy = sum(hit_top_k) * 1.0 / len(hit_top_k)\n",
    "        print(f\"\\tTop{k}: {100 * accuracy:.2f}%\")\n",
    "\n",
    "    def __train_once(self):\n",
    "        self.model.train()\n",
    "        self.__adjust_lr()\n",
    "        loader = self.data_loader[\"train\"]\n",
    "        loss_value = []\n",
    "\n",
    "        if self.meta_info[\"epoch\"] == 0:\n",
    "            print(\"loader length: \", len(loader))\n",
    "\n",
    "        self.meta_info[\"iter\"] = 0\n",
    "        for data, label in loader:\n",
    "            print(f\"iter: {self.meta_info['iter']}\")\n",
    "            # get data\n",
    "            data = data.float().to(self.dev)\n",
    "            label = label.long().to(self.dev)\n",
    "\n",
    "            # forward\n",
    "            output = self.model(data)\n",
    "            loss = self.loss(output, label)\n",
    "\n",
    "            # backward\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            loss_value.append(loss.data.item())\n",
    "            self.meta_info[\"iter\"] += 1\n",
    "\n",
    "        self.epoch_info[\"mean_loss\"] = np.mean(loss_value)\n",
    "\n",
    "    def __test(self, evaluation=True):\n",
    "        self.model.eval()\n",
    "        loader = self.data_loader[\"test\"]\n",
    "        loss_value = []\n",
    "        result_frag = []\n",
    "        label_frag = []\n",
    "\n",
    "        for data, label in loader:\n",
    "\n",
    "            # get data\n",
    "            data = data.float().to(self.dev)\n",
    "            label = label.long().to(self.dev)\n",
    "\n",
    "            # inference\n",
    "            with torch.no_grad():\n",
    "                output = self.model(data)\n",
    "            result_frag.append(output.data.cpu().numpy())\n",
    "\n",
    "            # get loss\n",
    "            if evaluation:\n",
    "                loss = self.loss(output, label)\n",
    "                loss_value.append(loss.item())\n",
    "                label_frag.append(label.data.cpu().numpy())\n",
    "\n",
    "        self.result = np.concatenate(result_frag)\n",
    "        if evaluation:\n",
    "            self.label = np.concatenate(label_frag)\n",
    "            self.epoch_info[\"mean_loss\"] = np.mean(loss_value)\n",
    "\n",
    "            for k, v in self.epoch_info.items():\n",
    "                print(f\"\\t{k}: {v}\")\n",
    "\n",
    "        for k in range(1, self.topk + 1):\n",
    "            self.__show_topk(k)\n",
    "\n",
    "    def train_once(self):\n",
    "        print(\"Start training\")\n",
    "        self.__train_once()\n",
    "        print(\"End of training\")\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(1, self.epoch + 1):\n",
    "            self.meta_info[\"epoch\"] = epoch\n",
    "            print(f\"Epoch: {self.meta_info['epoch']}\")\n",
    "            self.__train_once()\n",
    "\n",
    "            self.__save_model(self.model)\n",
    "\n",
    "    def test(self):\n",
    "        print(\"Start testing\")\n",
    "        self.__test()\n",
    "        print(\"End of testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been loaded from ./models/epoch_model.pt.\n",
      "Epoch: 1\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 2\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 3\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 4\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 5\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 6\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 7\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 8\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 9\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Epoch: 10\n",
      "iter: 0\n",
      "The model has been saved as ./models/epoch_model.pt.\n",
      "Start testing\n",
      "\tmean_loss: 1.493636965751648\n",
      "\tTop1: 33.33%\n",
      "\tTop2: 66.67%\n",
      "\tTop3: 100.00%\n",
      "End of testing\n"
     ]
    }
   ],
   "source": [
    "p = ST_GCN_Processor(\n",
    "    \"./data/xsub/train_data.npy\",\n",
    "    \"./data/xsub/train_label.pkl\",\n",
    "    \"./data/xsub/val_data.npy\",\n",
    "    \"./data/xsub/val_label.pkl\",\n",
    "    epoch=10,\n",
    "    topk=3,\n",
    "    model_path=\"./models/epoch_model.pt\",\n",
    ")\n",
    "\n",
    "p.train()\n",
    "p.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
